{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_7B_init = pd.read_csv('inference_results_qwen_7B_init.csv')\n",
    "qwen_7B_sft = pd.read_csv('inference_results_qwen_7B_sft.csv')\n",
    "qwen_14B_init = pd.read_csv('inference_results_qwen_14B_init.csv')\n",
    "qwen_14B_sft = pd.read_csv('inference_results_qwen_14B_sft.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7B_init 0.25\n",
      "7B_sft 0.5433333333333333\n",
      "14B_init 0.38\n",
      "14B_sft 0.49\n"
     ]
    }
   ],
   "source": [
    "# 比较正确率,召回率,查准率, F1值\n",
    "acc_set = []\n",
    "recall_set = []\n",
    "precision_set = []\n",
    "f1_set = []\n",
    "\n",
    "data_set = [qwen_7B_init, qwen_7B_sft, qwen_14B_init, qwen_14B_sft]\n",
    "res_set = []\n",
    "for data in data_set:\n",
    "    res = []\n",
    "    for i in range(300):\n",
    "        label = data['Expected Output'][i]\n",
    "        pred = data['Generated Output'][i]\n",
    "        res.append([label, pred])\n",
    "    res_set.append(res)\n",
    "    \n",
    "\n",
    "# 计算正确率\n",
    "for i in range(4):\n",
    "    acc = 0\n",
    "    for j in range(300):\n",
    "        if res_set[i][j][0] == res_set[i][j][1]:\n",
    "            acc += 1\n",
    "    acc_set.append(acc / 300)\n",
    "\n",
    "# # 计算召回率\n",
    "# for i in range(4):\n",
    "#     tp = 0\n",
    "#     fn = 0\n",
    "#     for j in range(300):\n",
    "#         if res_set[i][j][0] == res_set[i][j][1] and res_set[i][j][0] == 1:\n",
    "#             tp += 1\n",
    "#         if res_set[i][j][0] == 1:\n",
    "#             fn += 1\n",
    "#     if tp + fn == 0:\n",
    "#         recall_set.append('-')\n",
    "#     else:\n",
    "#         recall_set.append(tp / (tp + fn))\n",
    "\n",
    "# # 计算查准率\n",
    "# for i in range(4):\n",
    "#     tp = 0\n",
    "#     fp = 0\n",
    "#     for j in range(300):\n",
    "#         if res_set[i][j][0] == res_set[i][j][1] and res_set[i][j][0] == 1:\n",
    "#             tp += 1\n",
    "#         if res_set[i][j][1] == 1:\n",
    "#             fp += 1\n",
    "#     if tp + fp == 0:\n",
    "#         precision_set.append('-')\n",
    "#     else:\n",
    "#         precision_set.append(tp / (tp + fp))\n",
    "\n",
    "# # 计算F1值\n",
    "# for i in range(4):\n",
    "#     if precision_set[i] == '-' or recall_set[i] == '-':\n",
    "#         f1_set.append('-')\n",
    "#     else:\n",
    "#         f1 = 2 * precision_set[i] * recall_set[i] / (precision_set[i] + recall_set[i])\n",
    "#         if precision_set[i] == '-' or recall_set[i] == '-':\n",
    "#             f1_set.append('-')\n",
    "#         else:\n",
    "#             f1_set.append(f1)\n",
    "print('7B_init:', acc_set[0])\n",
    "print('7B_sft:', acc_set[1])\n",
    "print('14B_init:', acc_set[2])\n",
    "print('14B_sft:', acc_set[3])\n",
    "# print(recall_set)\n",
    "# print(precision_set)\n",
    "# print(f1_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for qwen_7B_init:\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.4802\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.2814\n",
      "------------------------------\n",
      "Results for qwen_7B_sft:\n",
      "Accuracy: 0.5433\n",
      "Precision: 0.4963\n",
      "Recall: 0.5433\n",
      "F1 Score: 0.5186\n",
      "------------------------------\n",
      "Results for qwen_14B_init:\n",
      "Accuracy: 0.3800\n",
      "Precision: 0.4226\n",
      "Recall: 0.3800\n",
      "F1 Score: 0.3952\n",
      "------------------------------\n",
      "Results for qwen_14B_sft:\n",
      "Accuracy: 0.4900\n",
      "Precision: 0.4502\n",
      "Recall: 0.4900\n",
      "F1 Score: 0.4693\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "data_set = [qwen_7B_init, qwen_7B_sft, qwen_14B_init, qwen_14B_sft]\n",
    "res_set = []\n",
    "\n",
    "# 存储结果：每个数据集的标签和预测\n",
    "for data in data_set:\n",
    "    res = []\n",
    "    for i in range(300):\n",
    "        label = data['Expected Output'][i]\n",
    "        pred = data['Generated Output'][i]\n",
    "        res.append([label, pred])\n",
    "    res_set.append(res)\n",
    "\n",
    "# 计算正确率、Precision、Recall 和 F1 score\n",
    "acc_set = []\n",
    "precision_set = []\n",
    "recall_set = []\n",
    "f1_set = []\n",
    "\n",
    "for i in range(4):\n",
    "    labels = [res_set[i][j][0] for j in range(300)]\n",
    "    preds = [res_set[i][j][1] for j in range(300)]\n",
    "    \n",
    "    # 计算正确率\n",
    "    acc = sum(1 for j in range(300) if labels[j] == preds[j]) / 300\n",
    "    acc_set.append(acc)\n",
    "    \n",
    "    # 计算 Precision, Recall, F1 Score（macro 平均）\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    precision_set.append(precision)\n",
    "    recall_set.append(recall)\n",
    "    f1_set.append(f1)\n",
    "\n",
    "# 输出结果\n",
    "for i, model in enumerate(['qwen_7B_init', 'qwen_7B_sft', 'qwen_14B_init', 'qwen_14B_sft']):\n",
    "    print(f\"Results for {model}:\")\n",
    "    print(f\"Accuracy: {acc_set[i]:.4f}\")\n",
    "    print(f\"Precision: {precision_set[i]:.4f}\")\n",
    "    print(f\"Recall: {recall_set[i]:.4f}\")\n",
    "    print(f\"F1 Score: {f1_set[i]:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for qwen_7B_init:\n",
      "  Class: high\n",
      "    Accuracy: 0.4500\n",
      "    Precision: 0.6222\n",
      "    Recall: 0.1591\n",
      "    F1 Score: 0.2534\n",
      "  Class: low\n",
      "    Accuracy: 0.9567\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "  Class: medium\n",
      "    Accuracy: 0.5267\n",
      "    Precision: 0.3456\n",
      "    Recall: 0.4700\n",
      "    F1 Score: 0.3983\n",
      "  Class: very high\n",
      "    Accuracy: 0.8200\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "Results for qwen_7B_sft:\n",
      "  Class: high\n",
      "    Accuracy: 0.5633\n",
      "    Precision: 0.6142\n",
      "    Recall: 0.6875\n",
      "    F1 Score: 0.6488\n",
      "  Class: low\n",
      "    Accuracy: 0.9667\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "  Class: medium\n",
      "    Accuracy: 0.6033\n",
      "    Precision: 0.4078\n",
      "    Recall: 0.4200\n",
      "    F1 Score: 0.4138\n",
      "  Class: very high\n",
      "    Accuracy: 0.9533\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "Results for qwen_14B_init:\n",
      "  Class: high\n",
      "    Accuracy: 0.5233\n",
      "    Precision: 0.5954\n",
      "    Recall: 0.5852\n",
      "    F1 Score: 0.5903\n",
      "  Class: low\n",
      "    Accuracy: 0.9367\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "  Class: medium\n",
      "    Accuracy: 0.5733\n",
      "    Precision: 0.2200\n",
      "    Recall: 0.1100\n",
      "    F1 Score: 0.1467\n",
      "  Class: very high\n",
      "    Accuracy: 0.9433\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "----------------------------------------\n",
      "Results for qwen_14B_sft:\n",
      "  Class: high\n",
      "    Accuracy: 0.5200\n",
      "    Precision: 0.5833\n",
      "    Recall: 0.6364\n",
      "    F1 Score: 0.6087\n",
      "  Class: low\n",
      "    Accuracy: 0.9667\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "  Class: medium\n",
      "    Accuracy: 0.5400\n",
      "    Precision: 0.3241\n",
      "    Recall: 0.3500\n",
      "    F1 Score: 0.3365\n",
      "  Class: very high\n",
      "    Accuracy: 0.9533\n",
      "    Precision: 0.0000\n",
      "    Recall: 0.0000\n",
      "    F1 Score: 0.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data_set = [qwen_7B_init, qwen_7B_sft, qwen_14B_init, qwen_14B_sft]\n",
    "model_names = ['qwen_7B_init', 'qwen_7B_sft', 'qwen_14B_init', 'qwen_14B_sft']\n",
    "\n",
    "# 结果列表\n",
    "res_set = []\n",
    "\n",
    "# 提取标签和预测\n",
    "for data in data_set:\n",
    "    res = []\n",
    "    for i in range(300):\n",
    "        label = data['Expected Output'][i]\n",
    "        pred = data['Generated Output'][i]\n",
    "        res.append([label, pred])\n",
    "    res_set.append(res)\n",
    "\n",
    "# 计算每个类别的指标\n",
    "for i, model in enumerate(model_names):\n",
    "    print(f\"Results for {model}:\")\n",
    "    \n",
    "    labels = [res_set[i][j][0] for j in range(300)]\n",
    "    preds = [res_set[i][j][1] for j in range(300)]\n",
    "    \n",
    "    # 获取所有唯一类别\n",
    "    classes = np.unique(labels)\n",
    "    \n",
    "    # 为每个类别计算指标\n",
    "    for cls in classes:\n",
    "        cls_labels = [1 if label == cls else 0 for label in labels]\n",
    "        cls_preds = [1 if pred == cls else 0 for pred in preds]\n",
    "\n",
    "        \n",
    "        acc = accuracy_score(cls_labels, cls_preds)\n",
    "        precision = precision_score(cls_labels, cls_preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(cls_labels, cls_preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(cls_labels, cls_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        print(f\"  Class: {cls}\")\n",
    "        print(f\"    Accuracy: {acc:.4f}\")\n",
    "        print(f\"    Precision: {precision:.4f}\")\n",
    "        print(f\"    Recall: {recall:.4f}\")\n",
    "        print(f\"    F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high', 'low', 'medium', 'very high'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
