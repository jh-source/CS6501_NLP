### examples/inference/llama3_lora_sft.yaml
model_name_or_path: meta-llama/Llama-2-7b
template: llama2
infer_backend: huggingface #choicesï¼š [huggingface, vllm]